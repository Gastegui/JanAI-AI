{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 11:41:49.256324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733395309.401045    1163 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733395309.446143    1163 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 11:41:49.783825: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import shutil as sh\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos disponibles:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Usando la GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "print(\"Dispositivos disponibles:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configura la primera GPU visible\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(\"Usando la GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for fixing the structure of the FooDD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./Datasets/FooDD/\"):\n",
    "    sh.rmtree(\"./Datasets/FooDD/Mixed\")\n",
    "    sh.rmtree(\"./Datasets/FooDD/Net images\")\n",
    "    sh.rmtree(\"./Datasets/FooDD/Grape/3-IOS-4-Light Environment\") # This directory has tomato pictures but on the Grape dir. Also, those images are already on the tomato dir, so simply delete it\n",
    "    sh.move(\"./Datasets/FooDD/Grape & Apple\", \"./Datasets/FooDD/Grape_and_Apple\")\n",
    "\n",
    "    # This gets rid of the camera directories\n",
    "    for dirPath, _, files in os.walk(\"./Datasets/FooDD/\", topdown=False): # Iterates through all the directories of the dataset\n",
    "        for file in files:\n",
    "            dst = os.path.join(os.path.dirname(dirPath), file) # Save the destination path for the image (Egg/X/Y.img -> Egg/Y.img)\n",
    "\n",
    "            if os.path.exists(dst): # Probably no image will trigger this, but there are some images that are named IMG_XXX, so just in case\n",
    "                name, ext = os.path.splitext(file)\n",
    "                i = 1\n",
    "                while os.path.exists(dst): # This loop executing more than once is even less probable, but better safe than sorry\n",
    "                    dst = os.path.join(os.path.dirname(dirPath), f\"{name}_{i}{ext}\")\n",
    "                    i += 1\n",
    "\n",
    "            sh.move(os.path.join(dirPath, file), dst)\n",
    "\n",
    "        try:\n",
    "            os.rmdir(dirPath) # Try deleting the folder (as we moved all the images out)\n",
    "        except OSError: # If the folder isn't empty, an exception is thrown (Bananas' dirs will be deleted, but not the Banana directory)\n",
    "            pass\n",
    "\n",
    "    # Now, separate the images into train and validate sets\n",
    "    for dirPath, dirNames, files in os.walk(\"./Datasets/FooDD\"):\n",
    "        if len(files) != 0:\n",
    "            train_subdir = os.path.join(\"./Datasets/FooDD/train\",  os.path.relpath(dirPath, \"./Datasets/FooDD\")) # The relPath thing gives the name of the food\n",
    "            validate_subdir = os.path.join(\"./Datasets/FooDD/validate\",  os.path.relpath(dirPath, \"./Datasets/FooDD\"))\n",
    "            os.makedirs(train_subdir, exist_ok=True)\n",
    "            os.makedirs(validate_subdir, exist_ok=True)\n",
    "\n",
    "            random.shuffle(files) # shuffles the names so that it won't take the first 70%, but a \"random\" 70%\n",
    "            num_train = int(len(files) * 0.7)\n",
    "\n",
    "            archivos_train = files[:num_train]\n",
    "            archivos_validate = files[num_train:]\n",
    "\n",
    "            # Mover archivos\n",
    "            for file in archivos_train:\n",
    "                sh.move(os.path.join(dirPath, file), os.path.join(train_subdir, file))\n",
    "            for file in archivos_validate:\n",
    "                sh.move(os.path.join(dirPath, file), os.path.join(validate_subdir, file))\n",
    "            os.rmdir(dirPath) # Delete the empty dirs, as now they are separated into train and validate dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for fixing the Food-101 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./Datasets/food-101/\"):\n",
    "    file = open(\"./Datasets/food-101/meta/train.txt\")\n",
    "    list = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    for item in list:\n",
    "        os.makedirs(\"./Datasets/food-101/images/train/\"+item.split(\"/\")[0], exist_ok=True)\n",
    "        sh.move(\"./Datasets/food-101/images/\"+item[:-1]+\".jpg\", \"./Datasets/food-101/images/train/\"+item[:-1]+\".jpg\")\n",
    "\n",
    "    file = open(\"./Datasets/food-101/meta/test.txt\")\n",
    "    list = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    for item in list:\n",
    "        os.makedirs(\"./Datasets/food-101/images/validate/\"+item.split(\"/\")[0], exist_ok=True)\n",
    "        sh.move(\"./Datasets/food-101/images/\"+item[:-1]+\".jpg\", \"./Datasets/food-101/images/validate/\"+item[:-1]+\".jpg\")\n",
    "\n",
    "    for dirPath, _, _ in os.walk(\"./Datasets/food-101/images/\"):\n",
    "        try:\n",
    "            os.rmdir(dirPath)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dict with the paths of the images that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train classes: 101\n",
      "Total validation classes: 101\n",
      "Total train images: 75750\n",
      "Total validation images: 25250\n"
     ]
    }
   ],
   "source": [
    "trainSet = { }\n",
    "validateSet = { }\n",
    "\n",
    "totalTrain = 0\n",
    "totalValidate = 0\n",
    "\n",
    "def addDir(path: str, train: bool):\n",
    "    global totalTrain\n",
    "    global totalValidate\n",
    "    iterator = os.walk(path)\n",
    "    dst = \"\"\n",
    "    if train:\n",
    "        dst = \"./Datasets/Cleaned/train/\" + path.split(\"/\")[-1]\n",
    "    else:\n",
    "        dst = \"./Datasets/Cleaned/validate/\" + path.split(\"/\")[-1]\n",
    "    for dirPath, _, files in iterator:\n",
    "        if(len(files) != 0):\n",
    "            os.makedirs(dst + dirPath.split(\"/\")[-1], exist_ok=True)\n",
    "            if train:\n",
    "                trainSet[dirPath] = files\n",
    "                totalTrain += len(files)\n",
    "            else:\n",
    "                validateSet[dirPath] = files\n",
    "                totalValidate += len(files)\n",
    "\n",
    "# addDir(\"./Datasets/Tipical_Brazilian_Foods/train/\", True)\n",
    "# addDir(\"./Datasets/Tipical_Brazilian_Foods/valid/\", False)\n",
    "# addDir(\"./Datasets/FooDD/train/\", True)\n",
    "# addDir(\"./Datasets/FooDD/validate/\", False)\n",
    "\n",
    "addDir(\"./Datasets/food-101/images/train/\", True)\n",
    "addDir(\"./Datasets/food-101/images/validate/\", False)\n",
    "\n",
    "print(\"Total train classes: \" + str(len(trainSet.keys())))\n",
    "print(\"Total validation classes: \" + str(len(validateSet.keys())))\n",
    "print(\"Total train images: \" + str(totalTrain))\n",
    "print(\"Total validation images: \" + str(totalValidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image preprocessing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "def preprocess(src: str, train: bool, dst: str = None):\n",
    "    image = Image.open(src)\n",
    "\n",
    "    # image.thumbnail((img_size, img_size), Image.BICUBIC)\n",
    "    # delta_w = img_size - image.size[0]\n",
    "    # delta_h = img_size - image.size[1]\n",
    "    # padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "    # image = ImageOps.expand(image, padding, fill=(255, 255, 255))\n",
    "\n",
    "    image.resize((img_size, img_size), Image.Resampling.HAMMING)\n",
    "\n",
    "    if image.mode in (\"RGBA\", \"LA\"): #If the image has transparency, get rid of it\n",
    "        background = Image.new(\"RGB\", image.size, (255, 255, 255)) #Create a white image to act as the background\n",
    "        background.paste(image, mask=image.split()[3]) #Apply this background where there is transparency on the image\n",
    "        image = background\n",
    "        \n",
    "    if dst == None:\n",
    "        if train:\n",
    "            dst = \"./Datasets/Cleaned/train/\" + \"/\".join(src.split(\"/\")[-2:])\n",
    "        else:\n",
    "            dst = \"./Datasets/Cleaned/validate/\" + \"/\".join(src.split(\"/\")[-2:])\n",
    "\n",
    "    if not (dst.endswith(\".jpg\") or dst.endswith(\".jpeg\")):\n",
    "        dst = \".\".join(dst.split(\".\")[:-1]) + \".jpg\"\n",
    "    image.save(dst, \"JPEG\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in trainSet.keys():\n",
    "    for image in trainSet[key]:\n",
    "        try:\n",
    "            preprocess(str(key) + \"/\" + image, True)\n",
    "        except Exception as e:\n",
    "            print(\"ERROR \" + str(key) + \"/\" + image + \": \" + str(e))\n",
    "\n",
    "for key in validateSet.keys():\n",
    "    for image in validateSet[key]:\n",
    "        try:\n",
    "            preprocess(str(key) + \"/\" + image, False)\n",
    "        except Exception as e:\n",
    "            print(\"ERROR \" + str(key) + \"/\" + image + \": \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75750 files belonging to 101 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733395389.380313    1163 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25250 files belonging to 101 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gastegui/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,813</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m16,777,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │        \u001b[38;5;34m51,813\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,922,789</span> (64.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,922,789\u001b[0m (64.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,922,789</span> (64.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,922,789\u001b[0m (64.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733395396.473755    1517 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 49ms/step - accuracy: 0.0356 - loss: 4.4418 - val_accuracy: 0.1039 - val_loss: 3.9298\n",
      "Epoch 2/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 49ms/step - accuracy: 0.1048 - loss: 3.9401 - val_accuracy: 0.1507 - val_loss: 3.6155\n",
      "Epoch 3/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - accuracy: 0.1441 - loss: 3.6724 - val_accuracy: 0.1749 - val_loss: 3.5117\n",
      "Epoch 4/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 50ms/step - accuracy: 0.1755 - loss: 3.5063 - val_accuracy: 0.1838 - val_loss: 3.4321\n",
      "Epoch 5/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - accuracy: 0.1919 - loss: 3.4115 - val_accuracy: 0.1989 - val_loss: 3.3461\n",
      "Epoch 6/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 45ms/step - accuracy: 0.2092 - loss: 3.3401 - val_accuracy: 0.2144 - val_loss: 3.2863\n",
      "Epoch 7/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - accuracy: 0.2163 - loss: 3.2821 - val_accuracy: 0.2112 - val_loss: 3.3043\n",
      "Epoch 8/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - accuracy: 0.2292 - loss: 3.2216 - val_accuracy: 0.2278 - val_loss: 3.2202\n",
      "Epoch 9/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - accuracy: 0.2397 - loss: 3.1698 - val_accuracy: 0.2010 - val_loss: 3.3890\n",
      "Epoch 10/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 51ms/step - accuracy: 0.2436 - loss: 3.1384 - val_accuracy: 0.2259 - val_loss: 3.2643\n",
      "Epoch 11/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 51ms/step - accuracy: 0.2521 - loss: 3.1005 - val_accuracy: 0.2400 - val_loss: 3.1662\n",
      "Epoch 12/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - accuracy: 0.2572 - loss: 3.0659 - val_accuracy: 0.2428 - val_loss: 3.1555\n",
      "Epoch 13/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 50ms/step - accuracy: 0.2667 - loss: 3.0310 - val_accuracy: 0.2449 - val_loss: 3.1476\n",
      "Epoch 14/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 51ms/step - accuracy: 0.2708 - loss: 3.0033 - val_accuracy: 0.2377 - val_loss: 3.2017\n",
      "Epoch 15/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 52ms/step - accuracy: 0.2777 - loss: 2.9757 - val_accuracy: 0.2415 - val_loss: 3.1649\n",
      "Epoch 16/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 49ms/step - accuracy: 0.2851 - loss: 2.9418 - val_accuracy: 0.2533 - val_loss: 3.1068\n",
      "Epoch 17/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 50ms/step - accuracy: 0.2845 - loss: 2.9247 - val_accuracy: 0.2551 - val_loss: 3.1263\n",
      "Epoch 18/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 50ms/step - accuracy: 0.2947 - loss: 2.8938 - val_accuracy: 0.2422 - val_loss: 3.2342\n",
      "Epoch 19/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 50ms/step - accuracy: 0.2968 - loss: 2.8759 - val_accuracy: 0.2457 - val_loss: 3.1808\n",
      "Epoch 20/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 50ms/step - accuracy: 0.3016 - loss: 2.8562 - val_accuracy: 0.2466 - val_loss: 3.1687\n",
      "Epoch 21/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 49ms/step - accuracy: 0.3051 - loss: 2.8377 - val_accuracy: 0.2553 - val_loss: 3.1307\n",
      "Epoch 22/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 49ms/step - accuracy: 0.3094 - loss: 2.8258 - val_accuracy: 0.2522 - val_loss: 3.1616\n",
      "Epoch 23/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 48ms/step - accuracy: 0.3161 - loss: 2.7857 - val_accuracy: 0.2459 - val_loss: 3.2259\n",
      "Epoch 24/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 46ms/step - accuracy: 0.3162 - loss: 2.7860 - val_accuracy: 0.2450 - val_loss: 3.2273\n",
      "Epoch 25/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 50ms/step - accuracy: 0.3198 - loss: 2.7521 - val_accuracy: 0.2652 - val_loss: 3.1023\n",
      "Epoch 26/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 49ms/step - accuracy: 0.3273 - loss: 2.7388 - val_accuracy: 0.2699 - val_loss: 3.0840\n",
      "Epoch 27/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 49ms/step - accuracy: 0.3234 - loss: 2.7322 - val_accuracy: 0.2293 - val_loss: 3.3200\n",
      "Epoch 28/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 50ms/step - accuracy: 0.3315 - loss: 2.7048 - val_accuracy: 0.2531 - val_loss: 3.1881\n",
      "Epoch 29/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 48ms/step - accuracy: 0.3353 - loss: 2.6907 - val_accuracy: 0.2551 - val_loss: 3.1995\n",
      "Epoch 30/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 43ms/step - accuracy: 0.3400 - loss: 2.6720 - val_accuracy: 0.2447 - val_loss: 3.3011\n",
      "Epoch 31/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3401 - loss: 2.6660 - val_accuracy: 0.2516 - val_loss: 3.2120\n",
      "Epoch 32/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3441 - loss: 2.6464 - val_accuracy: 0.2441 - val_loss: 3.3058\n",
      "Epoch 33/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 47ms/step - accuracy: 0.3462 - loss: 2.6342 - val_accuracy: 0.2587 - val_loss: 3.2182\n",
      "Epoch 34/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 49ms/step - accuracy: 0.3461 - loss: 2.6350 - val_accuracy: 0.2291 - val_loss: 3.4522\n",
      "Epoch 35/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3544 - loss: 2.6057 - val_accuracy: 0.2217 - val_loss: 3.4803\n",
      "Epoch 36/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3511 - loss: 2.6056 - val_accuracy: 0.2564 - val_loss: 3.2134\n",
      "Epoch 37/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3560 - loss: 2.5954 - val_accuracy: 0.2568 - val_loss: 3.2095\n",
      "Epoch 38/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3602 - loss: 2.5694 - val_accuracy: 0.2443 - val_loss: 3.3443\n",
      "Epoch 39/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3604 - loss: 2.5675 - val_accuracy: 0.2504 - val_loss: 3.2992\n",
      "Epoch 40/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3636 - loss: 2.5496 - val_accuracy: 0.2540 - val_loss: 3.2870\n",
      "Epoch 41/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3708 - loss: 2.5357 - val_accuracy: 0.2571 - val_loss: 3.2765\n",
      "Epoch 42/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3685 - loss: 2.5363 - val_accuracy: 0.2412 - val_loss: 3.4359\n",
      "Epoch 43/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3689 - loss: 2.5152 - val_accuracy: 0.2625 - val_loss: 3.2366\n",
      "Epoch 44/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3735 - loss: 2.5127 - val_accuracy: 0.2495 - val_loss: 3.3613\n",
      "Epoch 45/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3756 - loss: 2.4981 - val_accuracy: 0.2583 - val_loss: 3.2842\n",
      "Epoch 46/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3795 - loss: 2.4816 - val_accuracy: 0.2579 - val_loss: 3.3200\n",
      "Epoch 47/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3757 - loss: 2.4930 - val_accuracy: 0.2529 - val_loss: 3.3581\n",
      "Epoch 48/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3819 - loss: 2.4646 - val_accuracy: 0.2614 - val_loss: 3.2633\n",
      "Epoch 49/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3836 - loss: 2.4665 - val_accuracy: 0.2681 - val_loss: 3.2812\n",
      "Epoch 50/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3853 - loss: 2.4480 - val_accuracy: 0.2650 - val_loss: 3.2598\n",
      "Epoch 51/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 43ms/step - accuracy: 0.3880 - loss: 2.4328 - val_accuracy: 0.2474 - val_loss: 3.3891\n",
      "Epoch 52/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 43ms/step - accuracy: 0.3945 - loss: 2.4218 - val_accuracy: 0.2509 - val_loss: 3.4560\n",
      "Epoch 53/100\n",
      "\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - accuracy: 0.3891 - loss: 2.4259 - val_accuracy: 0.2397 - val_loss: 3.5323\n",
      "Epoch 54/100\n",
      "\u001b[1m 682/2368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 39ms/step - accuracy: 0.3931 - loss: 2.4209"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Graficar resultados\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configuración\n",
    "IMG_SIZE = (img_size, img_size)  # Tamaño de las imágenes (ya están preprocesadas)\n",
    "BATCH_SIZE = 32        # Tamaño del batch\n",
    "EPOCHS = 100            # Número de épocas\n",
    "\n",
    "# Directorios de datos\n",
    "TRAIN_DIR = \"./Datasets/Cleaned/train\"  # Cambia esto por la ruta a tu carpeta de entrenamiento\n",
    "VAL_DIR = \"./Datasets/Cleaned/validate\"  # Cambia esto por la ruta a tu carpeta de validación\n",
    "\n",
    "# Cargar datasets desde los directorios\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    image_size=IMG_SIZE,  # Las imágenes ya deberían tener este tamaño\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\",  # Las clases serán one-hot encoded\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Aumentación de datos (solo para entrenamiento)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\",  input_shape=(img_size, img_size, 3)),\n",
    "    tf.keras.layers.RandomRotation(factor=(0.1)),\n",
    "    tf.keras.layers.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "# Construcción del modelo\n",
    "model = models.Sequential([\n",
    "    data_augmentation,  # Aumentación para los datos de entrenamiento\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(32, 3, padding='same', activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, 3, padding='same', activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(128, 3, padding='same', activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    # layers.Dropout(0.2),  # Regularización para prevenir sobreajuste\n",
    "    layers.Dense(len(trainSet.keys()), activation=\"softmax\")  # cantidad de clases\n",
    "])\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenamiento\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# Graficar resultados\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs_range = range(EPOCHS)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label=\"Entrenamiento\")\n",
    "    plt.plot(epochs_range, val_acc, label=\"Validación\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Precisión\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label=\"Entrenamiento\")\n",
    "    plt.plot(epochs_range, val_loss, label=\"Validación\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Pérdida\")\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict(path: str):\n",
    "    # Cargar la imagen y redimensionarla al tamaño que espera el modelo (en este caso 128x128)\n",
    "    img = image.load_img(path)\n",
    "\n",
    "    # Convertir la imagen a un array numpy y agregar una dimzensión extra para que sea compatible con el modelo\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Esto convierte la forma de (128, 128, 3) en (1, 128, 128, 3)\n",
    "\n",
    "    # Normalizar la imagen (si es necesario, según el preprocesamiento que hayas hecho en el entrenamiento)\n",
    "    img_array = img_array / 255.0  # Normalizar a [0, 1] si lo hiciste en el entrenamiento\n",
    "\n",
    "    # Hacer la predicción\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    print(predictions)\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    class_names = [\"Acaraje\", \"Apple\", \"Arroz_com_pequi\", \"Arroz de cuxa\", \"Banana\", \"Barreado\", \"Bean\", \"Bread\", \"Carrot\", \"Cheese\", \"Churrasco\", \"Cucumber\", \"Egg\", \"Eisben\", \"Feijoada\", \"Grape\", \"Matrinxa\", \"Moqueca_capixaba\", \"Onion\", \"Orange\", \"Pao_de_queijo\", \"Pasta\", \"Pato_no_Tucupi\", \"Pepper\", \"Qiwi\", \"Sauce\", \"Tacaca\", \"Tomato\", \"Watermelon\"]  # Cambia estos nombres por los correctos\n",
    "\n",
    "    predicted_class = class_names[predicted_class_index]\n",
    "    print(f\"La imagen es de: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "[[1.00732817e-13 8.06684718e-02 1.04891569e-23 1.05047944e-19\n",
      "  1.24947450e-28 3.35337928e-17 2.91395481e-25 1.37752391e-21\n",
      "  4.90884833e-10 1.49144994e-19 6.59206378e-09 1.43394973e-30\n",
      "  2.22952741e-22 1.62370182e-21 3.84831595e-20 1.11162652e-08\n",
      "  6.43999316e-29 8.25558715e-23 3.43674155e-17 4.94698465e-01\n",
      "  7.90033751e-18 1.31856612e-20 6.67763987e-19 1.36512084e-21\n",
      "  2.09090099e-01 5.41722006e-17 2.05402183e-23 2.15425134e-01\n",
      "  1.17743082e-04 5.09530480e-08]]\n",
      "La imagen es de: Orange\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[[6.11599096e-12 6.18809164e-02 7.34128802e-16 3.08490958e-14\n",
      "  1.71374379e-16 1.07547028e-14 4.06493678e-20 2.52023278e-06\n",
      "  5.33876062e-07 2.23859817e-13 8.56350102e-10 8.10962327e-23\n",
      "  8.32837177e-09 1.96000340e-16 1.36488755e-17 2.68025026e-02\n",
      "  6.50278830e-21 3.11607994e-18 2.16144004e-15 8.65503609e-01\n",
      "  1.05741620e-14 3.00603964e-12 5.21493516e-16 1.60142911e-17\n",
      "  2.56962283e-03 3.46342677e-10 2.29241923e-17 3.78734693e-02\n",
      "  5.36686834e-03 1.72152570e-11]]\n",
      "La imagen es de: Orange\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[[6.8572067e-14 1.2568866e-02 1.1507047e-18 1.6365375e-16 4.4243560e-22\n",
      "  5.2531640e-17 3.0274210e-22 8.7653058e-09 5.1546017e-11 3.6893294e-17\n",
      "  3.2721423e-11 9.8109392e-26 2.1086122e-11 2.6377285e-19 3.1779458e-20\n",
      "  4.5407493e-02 3.8258073e-22 2.1791819e-21 2.0329992e-18 9.4188452e-01\n",
      "  2.7435376e-18 4.7169647e-15 8.7958747e-19 1.2018541e-19 4.5569168e-06\n",
      "  1.1577123e-14 1.0912195e-20 9.4785864e-05 3.9785748e-05 2.4789735e-13]]\n",
      "La imagen es de: Orange\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[[1.2507560e-11 4.9172284e-04 3.1200761e-13 2.4222779e-13 1.0200139e-15\n",
      "  8.1463184e-14 1.1444670e-17 2.9178581e-01 3.0594018e-09 1.6798683e-12\n",
      "  8.5241302e-12 1.5970314e-22 5.0068437e-04 7.2670345e-14 5.7007948e-18\n",
      "  4.5348740e-01 1.4564655e-17 4.0459554e-18 3.4475162e-16 2.5267014e-01\n",
      "  1.2525995e-14 1.7174010e-08 2.2917652e-14 2.1097733e-16 5.5480587e-08\n",
      "  2.0463492e-12 1.1601998e-16 1.0474197e-03 1.6752969e-05 3.1629479e-13]]\n",
      "La imagen es de: Grape\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "[[8.5995822e-10 4.6564523e-02 5.6037531e-12 2.3655675e-11 1.0187962e-12\n",
      "  1.7029966e-11 1.0375102e-15 1.5866429e-02 3.4171303e-06 1.8854705e-10\n",
      "  6.6381385e-09 5.7792773e-19 1.3511050e-04 1.1908979e-12 6.1805305e-15\n",
      "  2.7415541e-01 3.3805442e-16 2.1696281e-15 3.4731221e-13 5.2614170e-01\n",
      "  1.3969166e-11 3.4982484e-08 5.3373157e-12 6.6935166e-14 4.1951714e-04\n",
      "  5.7349441e-09 3.2457869e-14 1.3392471e-01 2.7890725e-03 2.9840230e-10]]\n",
      "La imagen es de: Orange\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[[1.6324142e-10 7.5299450e-10 2.4007434e-08 8.0494283e-10 3.8192489e-08\n",
      "  2.8485697e-10 1.2691358e-13 9.9970680e-01 8.4150829e-09 9.3598123e-07\n",
      "  1.9977157e-10 8.6841783e-16 2.1483259e-04 1.5925647e-08 3.7528608e-14\n",
      "  2.0382863e-07 7.8961886e-11 1.2371704e-14 3.1500448e-13 4.1093134e-08\n",
      "  1.3759861e-11 7.7226301e-05 9.0955108e-12 1.2309740e-12 6.3504581e-14\n",
      "  1.9857282e-12 4.4579312e-11 3.6001211e-09 5.0957638e-10 1.2877393e-15]]\n",
      "La imagen es de: Bread\n"
     ]
    }
   ],
   "source": [
    "preprocess(\"./Predictions/Raw/1.jpg\", False, \"./Predictions/Ready/1.jpg\")\n",
    "preprocess(\"./Predictions/Raw/2.jpg\", False, \"./Predictions/Ready/2.jpg\")\n",
    "preprocess(\"./Predictions/Raw/3.jpg\", False, \"./Predictions/Ready/3.jpg\")\n",
    "preprocess(\"./Predictions/Raw/4.jpg\", False, \"./Predictions/Ready/4.jpg\")\n",
    "preprocess(\"./Predictions/Raw/5.jpg\", False, \"./Predictions/Ready/5.jpg\")\n",
    "preprocess(\"./Predictions/Raw/6.jpg\", False, \"./Predictions/Ready/6.jpg\")\n",
    "\n",
    "predict(\"./Predictions/Ready/1.jpg\")\n",
    "predict(\"./Predictions/Ready/2.jpg\")\n",
    "predict(\"./Predictions/Ready/3.jpg\")\n",
    "predict(\"./Predictions/Ready/4.jpg\")\n",
    "predict(\"./Predictions/Ready/5.jpg\")\n",
    "predict(\"./Predictions/Ready/6.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
