{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-qa-catan2-27be76ac' at:\n",
      "https://smith.langchain.com/o/d8732a95-694b-4861-8708-e595c54cc5a7/datasets/ae62608f-6e80-4a3b-91ab-a1a27aebbd46/compare?selectedSessions=7aaf1425-5eb9-47a5-8b9f-6ed683f2f184\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Yesterday I ate fried food, how can I detox my body today?\n",
      "Username:  iamLudok\n",
      "Question:  I want to build muscle. What should I include in my meals?\n",
      "Username:  iamLudok\n",
      "Question:  What can I eat before going for a run to have more energy?\n",
      "Username:  iamLudok\n",
      "Question:  I have high cholesterol, what should I avoid eating?\n",
      "Username:  iamLudok\n",
      "Question:  I'm lactose intolerant, what snacks are safe for me?\n",
      "Username:  iamLudok\n",
      "Question:  Can you suggest a high-protein breakfast for me?\n",
      "Username:  iamLudok\n",
      "Question:  If yesterday I didn't drink any water, how much water should I drink today?\n",
      "Username:  iamLudok\n",
      "Question:  I want to lose weight but I love desserts. What dessert can I eat?\n",
      "Username:  iamLudok\n",
      "Question:  I am diabetic, what can I eat today according to my condition?\n",
      "Username:  iamLudok\n",
      "Question:  I have an important lunch this weekend and I will eat a lot, what should I eat the next day to balance my diet?\n",
      "Username:  iamLudok\n",
      "Question:  Today I will ate pasta for lunch, what can I add to the pasta to make it tastier?\n",
      "Username:  iamLudok\n",
      "Question:  If I were allergic to peanuts, what couldn't I eat?\n",
      "Username:  iamLudok\n",
      "Question:  I have diarrhea, what should I eat?\n",
      "Username:  iamLudok\n",
      "Question:  Yesterday I ate a hamburger, what should i eat today to avoid gaining weight?\n",
      "Username:  iamLudok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [3:31:29, 906.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import mysql.connector\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "\n",
    "\n",
    "def get_db_connection():\n",
    "    return mysql.connector.connect(\n",
    "        host=os.getenv('HOST'),\n",
    "        user=os.getenv('USER'),\n",
    "        password=os.getenv('PASS'),\n",
    "        database=os.getenv('DB'),\n",
    "    )\n",
    "\n",
    "CHROMA_PATH = 'chroma'\n",
    "\n",
    "PROMPT_SYSTEM = \"\"\"\n",
    "# Role and Identity\n",
    "You are Janai, an AI nutrition assistant specializing in personalized dietary recommendations. You provide evidence-based nutrition advice while maintaining a supportive and encouraging tone.\n",
    "\n",
    "# User Profile\n",
    "Personal Information:\n",
    "- Name: {name}\n",
    "- Height: {height} cm\n",
    "- Weight: {weight} kg\n",
    "- Age: {age}\n",
    "- Activity Level: {activityLevel}\n",
    "- Health Goal: {goal}\n",
    "\n",
    "Dietary Considerations:\n",
    "- Restrictions: {restrictions}\n",
    "- Recent Meals: {user_eaten_food}\n",
    "\n",
    "# Behavioral Guidelines\n",
    "1. Never recommend foods containing listed restrictions\n",
    "2. Consider recent meals when making suggestions to ensure variety\n",
    "3. Tailor portions and caloric recommendations to activity level\n",
    "4. Always account for stated health goals in recommendations\n",
    "5. Base all advice on provided context and scientific evidence\n",
    "6. Provide brief explanations for nutritional recommendations\n",
    "\n",
    "# Response Format\n",
    "- Keep responses concise and actionable\n",
    "- Structure recommendations in clear sections\n",
    "- Include approximate nutritional values when relevant\n",
    "- Suggest practical alternatives for restricted foods\n",
    "\n",
    "Context for recommendations:\n",
    "{context}\n",
    "\"\"\"\n",
    "PROMP_HUMAN = \"\"\"\n",
    "Based on your nutrition expertise and the above context, please address: {input}\n",
    "\"\"\"\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "def get_user_food(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT fo.foodName, f.consumptionDate, f.meal FROM foodList f JOIN food fo ON f.foodID=fo.foodID JOIN userData u ON f.userID=u.userID WHERE u.username = %s AND f.consumptionDate >= DATE_SUB(CURDATE(), INTERVAL 7 DAY)'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_height(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT height FROM userData WHERE username = %s'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_weight(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT weight FROM weightgoals w JOIN userData u ON w.userID=u.userID WHERE username = %s'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_age(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT age FROM userData WHERE username = %s'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_activity_level(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT activityLevel FROM userData WHERE username = %s'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_goal(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT objective FROM userData WHERE username = %s'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "def get_food(db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT * FROM food'\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_user(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT uname FROM userdata where username = %s'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_user_restrictions(username, db):\n",
    "    cursor = db.cursor(dictionary=True)\n",
    "    query = 'SELECT fg.groupName, fc.className, ft.typeName, i.ingName from restrictions r JOIN foodGroup fg ON fg.groupID=r.groupID JOIN foodClass fc ON fc.classID=r.classID JOIN foodType ft ON ft.typeID=r.typeID JOIN ingredients i ON i.ingredientID=r.ingredientID JOIN userData u ON r.userID=u.userID where u.username = %s'\n",
    "    cursor.execute(query, (username,))\n",
    "    result = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_embedding_function():\n",
    "    embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def create_chain():\n",
    "    embedding_function = get_embedding_function()\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    llm = OllamaLLM(model='llama3:latest', temperature=0.3)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [('system', PROMPT_SYSTEM), ('user', PROMP_HUMAN)]\n",
    "    )\n",
    "\n",
    "    chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "    retrieval_chain = create_retrieval_chain(retriever, chain)\n",
    "\n",
    "    return retrieval_chain\n",
    "\n",
    "\n",
    "def process_chat(\n",
    "    chain,\n",
    "    question,\n",
    "    user_eaten_food,\n",
    "    food,\n",
    "    user,\n",
    "    user_restrictions,\n",
    "    height,\n",
    "    weight,\n",
    "    age,\n",
    "    activity_level,\n",
    "    goal,\n",
    "):\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            'user_eaten_food': user_eaten_food,\n",
    "            'food': food,\n",
    "            'name': user,\n",
    "            'restrictions': user_restrictions,\n",
    "            'input': question,\n",
    "            'height': height,\n",
    "            'weight': weight,\n",
    "            'age': age,\n",
    "            'activityLevel': activity_level,\n",
    "            'goal': goal,\n",
    "        }\n",
    "    )\n",
    "    return response['answer']\n",
    "\n",
    "\n",
    "def chat(data):\n",
    "    with get_db_connection() as db:\n",
    "        user_input = data.get('question', '')\n",
    "        username = data.get('username', '')\n",
    "\n",
    "        print('Question: ', user_input)\n",
    "        print('Username: ', username)\n",
    "\n",
    "        user_food =  get_user_food(username=username, db=db)\n",
    "        food = get_food(db=db)\n",
    "        user = get_user(username=username, db=db)\n",
    "        user_restrictions = get_user_restrictions(username=username, db=db)\n",
    "        height =  get_height(username=username, db=db)\n",
    "        weight = get_weight(username=username, db=db)\n",
    "        age = get_age(username=username, db=db)\n",
    "        activity_level = get_activity_level(username=username, db=db)\n",
    "        goal = get_goal(username=username, db=db)\n",
    "\n",
    "        chain = create_chain()\n",
    "\n",
    "        response = process_chat(\n",
    "            chain=chain,\n",
    "            question=user_input,\n",
    "            user_eaten_food=user_food,\n",
    "            food=food,\n",
    "            user=user,\n",
    "            user_restrictions=user_restrictions,\n",
    "            height=height,\n",
    "            weight=weight,\n",
    "            age=age,\n",
    "            activity_level=activity_level,\n",
    "            goal=goal,\n",
    "        )\n",
    "\n",
    "    return response\n",
    "\n",
    "import os\n",
    "os.environ['LANGSMITH_TRACING']\n",
    "os.environ['LANGSMITH_ENDPOINT']\n",
    "os.environ['LANGSMITH_API_KEY']\n",
    "os.environ['LANGSMITH_PROJECT'] \n",
    "\n",
    "# QA\n",
    "inputs = [\n",
    "    \"Yesterday I ate a hamburger, what should i eat today to avoid gaining weight?\",\n",
    "    \"I have diarrhea, what should I eat?\",\n",
    "    \"If I were allergic to peanuts, what couldn't I eat?\",\n",
    "    \"Today I will ate pasta for lunch, what can I add to the pasta to make it tastier?\",\n",
    "    \"I am diabetic, what can I eat today according to my condition?\", \n",
    "    \"I have an important lunch this weekend and I will eat a lot, what should I eat the next day to balance my diet?\",\n",
    "    \"If yesterday I didn't drink any water, how much water should I drink today?\",\n",
    "    \"I want to lose weight but I love desserts. What dessert can I eat?\", \n",
    "    \"I'm lactose intolerant, what snacks are safe for me?\",\n",
    "    \"Can you suggest a high-protein breakfast for me?\",\n",
    "    \"I have high cholesterol, what should I avoid eating?\",\n",
    "    \"I want to build muscle. What should I include in my meals?\", \n",
    "    \"Yesterday I ate fried food, how can I detox my body today?\",\n",
    "    \"What can I eat before going for a run to have more energy?\"\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"Considering your dietary restrictions and preferences, I'd recommend avoiding foods high in calories and saturated fats. Given that you had a burger yesterday, let's focus on healthier options.\",\n",
    "    \"For your diarrhea issue, it's essential to focus on easily digestible foods. Here are some suggestions: bananas and rice.\",\n",
    "    \"You should avoid foods that contain peanuts, such as peanut butter, peanut sauce, and peanut oil.\",\n",
    "    \"I'd recommend adding something to your pasta.\",\n",
    "    \"As a diabetic, it's essential to focus on foods that can help manage blood sugar levels and provide sustained energy.\", \n",
    "    \"Since you're planning a big lunch this weekend and expecting to eat a lot, it's essential to balance your diet the next day.\",\n",
    "    \"Your body needs water to function properly, especially when you're not drinking enough. Since you didn't drink any water yesterday, it's essential to replenish your fluids today!\",\n",
    "    \"As a nutritional expert, I understand that you're looking for a dessert option that fits your goal of losing weight while still satisfying your sweet tooth.\", \n",
    "    \"Since you're lactose intolerant, I'll recommend some delicious and safe snack options that don't include dairy products.\",\n",
    "    \"I recommend a balanced breakfast that combines protein with complex carbohydrates. Here's a suggestion:\",\n",
    "    \"It's crucial to limit or avoid foods that are high in saturated and trans fats. Here are some recommendations:\",\n",
    "    \"Given that you're looking to build muscle, we'll focus on increasing protein intake while maintaining a balanced diet. Here are some food suggestions:\", \n",
    "    \"By incorporating these foods into your diet, you'll be supporting your body's natural detoxification processes and helping to counteract the effects of yesterday's fried food consumption.\",\n",
    "    \"I'll recommend some foods that will give you a boost of energy before your run.\"\n",
    "]\n",
    "\n",
    "std_response = \"No se encontraron entrada\"\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"Janai\"\n",
    "evaluation_llm = OllamaLLM(model=\"llama3:latest\", temperature=0)\n",
    "\n",
    "# Store\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Dataset for Janai\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q, \"username\": \"iamLudok\"} for q in inputs],\n",
    "    outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")\n",
    "\n",
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "qa_evalulator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    prepare_data = lambda run, example: {\n",
    "        \"prediction\": str(run.outputs),\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": str(example.inputs) if hasattr(example, \"inputs\") else std_response,\n",
    "    },\n",
    "    config={ \"llm\": evaluation_llm }\n",
    ")\n",
    "\n",
    "answer_hallucination_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_score_string\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"accuracy\": \"\"\"Is the Assistant's Answer grounded in the Ground Truth documentation? A score of [[1]] means that the\n",
    "            Assistant answer contains is not at all based upon / grounded in the Groun Truth documentation. A score of [[5]] means \n",
    "            that the Assistant answer contains some information (e.g., a hallucination) that is not captured in the Ground Truth \n",
    "            documentation. A score of [[10]] means that the Assistant answer is fully based upon the in the Ground Truth documentation.\"\"\"\n",
    "        },\n",
    "        # If you want the score to be saved on a scale from 0 to 1\n",
    "        \"normalize_by\": 10,\n",
    "        \"llm\": evaluation_llm\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"output\"],\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": str(example.inputs) if hasattr(example, \"inputs\") else std_response,\n",
    "    }\n",
    ")\n",
    "\n",
    "import textwrap\n",
    "docs_relevance_evaluator = LangChainStringEvaluator(\n",
    "    \"score_string\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"document_relevance\": textwrap.dedent(\n",
    "                \"\"\"The response is a set of documents retrieved from a vectorstore. The input is a question\n",
    "            used for retrieval. You will score whether the Assistant's response (retrieved docs) is relevant to the Ground Truth \n",
    "            question. A score of [[1]] means that none of the  Assistant's response documents contain information useful in answering or addressing the user's input.\n",
    "            A score of [[5]] means that the Assistant answer contains some relevant documents that can at least partially answer the user's question or input. \n",
    "            A score of [[10]] means that the user input can be fully answered using the content in the first retrieved doc(s).\"\"\"\n",
    "            )\n",
    "        },\n",
    "        # If you want the score to be saved on a scale from 0 to 1\n",
    "        \"normalize_by\": 10,\n",
    "        \"llm\": evaluation_llm\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"output\"],\n",
    "        \"input\": str(example.inputs) if hasattr(example, \"inputs\") else std_response,\n",
    "    }\n",
    ")\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    chat,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator, answer_hallucination_evaluator, docs_relevance_evaluator],\n",
    "    experiment_prefix=\"rag-qa-catan2\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langchain_core.prompts.prompt import PromptTemplate\\nfrom langsmith.evaluation import LangChainStringEvaluator\\nfrom langchain_community.llms import Ollama\\nfrom langsmith import traceable\\n\\n_PROMPT_TEMPLATE = \"\"You are an expert professor specialized in grading students\\' answers to questions.\\nYou are grading the following question:\\n{query}\\nHere is the real answer:\\n{answer}\\nYou are grading the following predicted answer:\\n{result}\\nRespond with CORRECT or INCORRECT:\\nGrade:\\n\"\"\\n\\nPROMPT = PromptTemplate(\\n    input_variables=[\"query\", \"answer\", \"result\"], template=_PROMPT_TEMPLATE\\n)\\n\\neval_llm = Ollama(model=\"llama3\", stop=[\"<|eot_id|>\"], temperature=0.4, top_k=3, top_p=0.9) # Added stop token\\nqa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm, \"prompt\": PROMPT})'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "from langchain_community.llms import Ollama\n",
    "from langsmith import traceable\n",
    "\n",
    "_PROMPT_TEMPLATE = \"\"You are an expert professor specialized in grading students' answers to questions.\n",
    "You are grading the following question:\n",
    "{query}\n",
    "Here is the real answer:\n",
    "{answer}\n",
    "You are grading the following predicted answer:\n",
    "{result}\n",
    "Respond with CORRECT or INCORRECT:\n",
    "Grade:\n",
    "\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\", \"result\"], template=_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "eval_llm = Ollama(model=\"llama3\", stop=[\"<|eot_id|>\"], temperature=0.4, top_k=3, top_p=0.9) # Added stop token\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\": eval_llm, \"prompt\": PROMPT})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langchain_community.llms import Ollama\\nfrom langchain import PromptTemplate # Added\\n\\nllm = Ollama(model=\"llama2\", stop=[\"<|eot_id|>\"]) # Added stop token\\n\\ndef get_model_response(user_prompt, system_prompt):\\n    # NOTE: No f string and no whitespace in curly braces\\n    template = \"\"\\n        <|begin_of_text|>\\n        <|start_header_id|>system<|end_header_id|>\\n        {system_prompt}\\n        <|eot_id|>\\n        <|start_header_id|>user<|end_header_id|>\\n        {user_prompt}\\n        <|eot_id|>\\n        <|start_header_id|>assistant<|end_header_id|>\\n        \"\"\\n\\n    # Added prompt template\\n    prompt = PromptTemplate(\\n        input_variables=[\"system_prompt\", \"user_prompt\"],\\n        template=template\\n    )\\n    \\n    # Modified invoking the model\\n    response = llm(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt))\\n    \\n    return response'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate # Added\n",
    "\n",
    "llm = Ollama(model=\"llama2\", stop=[\"<|eot_id|>\"]) # Added stop token\n",
    "\n",
    "def get_model_response(user_prompt, system_prompt):\n",
    "    # NOTE: No f string and no whitespace in curly braces\n",
    "    template = \"\"\n",
    "        <|begin_of_text|>\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "        {system_prompt}\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        {user_prompt}\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\n",
    "\n",
    "    # Added prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"system_prompt\", \"user_prompt\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    # Modified invoking the model\n",
    "    response = llm(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt))\n",
    "    \n",
    "    return response\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def langsmith_app(inputs):\\n    output = chat(inputs)\\n    #output = get_model_response(\"Respond to the users question in a short, concise manner (one short sentence).\", inputs[\"question\"])\\n    return {\"output\": output}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def langsmith_app(inputs):\n",
    "    output = chat(inputs)\n",
    "    #output = get_model_response(\"Respond to the users question in a short, concise manner (one short sentence).\", inputs[\"question\"])\n",
    "    return {\"output\": output}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langsmith.evaluation import evaluate\\n\\nexperiment_results = evaluate(\\n    langsmith_app, # Your AI system\\n    data=dataset_name, # The data to predict and grade over\\n    evaluators=[qa_evaluator], # The evaluators to score the results\\n    experiment_prefix=\"Llama-2-local-correctness\", # A prefix for your experiment names to easily identify them\\n)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from langsmith.evaluation import evaluate\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    langsmith_app, # Your AI system\n",
    "    data=dataset_name, # The data to predict and grade over\n",
    "    evaluators=[qa_evaluator], # The evaluators to score the results\n",
    "    experiment_prefix=\"Llama-2-local-correctness\", # A prefix for your experiment names to easily identify them\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_results._results[0].keys()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"experiment_results._results[0].keys()\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbl5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
